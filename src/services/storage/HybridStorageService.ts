/**
 * HybridStorageService - Supabase-First with AsyncStorage Cache
 *
 * This service prioritizes Supabase as the primary data source while using AsyncStorage
 * as a silent, background cache for offline-first functionality.
 *
 * Key principles:
 * - Reads: Try Supabase first â†’ fallback to AsyncStorage if offline
 * - Writes: Save to Supabase â†’ then update AsyncStorage cache silently
 * - No migration layer - users start fresh if no Supabase data exists
 */

import AsyncStorage from '@react-native-async-storage/async-storage';
import MMKVStorageService from './MMKVStorageService';
import { STORAGE_CONFIG } from '../../config/storage.config';
import { SupabaseStorageService } from './SupabaseStorageService';
import database from '../../database/database';
import syncQueue from './syncQueue';
import SpacedRepetitionService from '../learning/SpacedRepetitionService';
import {
  Task,
  StudySession,
  MemoryPalace,
  ProgressData,
  Settings,
  Flashcard,
} from '../../types';
import { validateTask } from './validators/taskValidator';
import { validateMemoryPalace } from './validators/memoryPalaceValidator';
import {
  SoundSettings,
  NeuralLogEntry,
  DistractionEvent,
  FocusSession,
  FocusHealthMetrics,
  LogicNode,
  NeuroplasticitySession,
  SynapseData,
} from './StorageService';
import { ReadingSession, SourceLink } from '../learning/SpeedReadingService';

export class HybridStorageService {
  private static instance: HybridStorageService;
  private supabaseService: SupabaseStorageService;
  private isOnline: boolean = true;

  // Add saveCognitiveSession method to HybridStorageService
  async saveCognitiveSession(sessionId: string, log: any): Promise<void> {
    try {
      // Try to save cognitive session data to Supabase
      await this.supabaseService.saveCognitiveSession(sessionId, log);
    } catch (error) {
      console.warn('Failed to save cognitive session to Supabase:', error);
      // Fallback: queue for sync locally
      await this.queueForSync('@neurolearn/cache_cognitive_sessions', { sessionId, log });
    }
  }

  // Cache keys for AsyncStorage
  private static readonly CACHE_KEYS = {
    FLASHCARDS: '@neurolearn/cache_flashcards',
    // Tasks, study sessions and memory palaces
    TASKS: '@neurolearn/cache_tasks',
    STUDY_SESSIONS: '@neurolearn/cache_study_sessions',
  MEMORY_PALACES: '@neurolearn/cache_memory_palaces',
    LOGIC_NODES: '@neurolearn/cache_logic_nodes',
    FOCUS_SESSIONS: '@neurolearn/cache_focus_sessions',
    READING_SESSIONS: '@neurolearn/cache_reading_sessions',
    SETTINGS: '@neurolearn/cache_settings',
    NEURAL_LOGS: '@neurolearn/cache_neural_logs',
    SOUND_SETTINGS: '@neurolearn/cache_sound_settings',
    FOCUS_HEALTH_METRICS: '@neurolearn/cache_focus_health_metrics',
    DISTRACTION_EVENTS: '@neurolearn/cache_distraction_events',
    SOURCE_LINKS: '@neurolearn/cache_source_links',
    COGNITIVE_METRICS: '@neurolearn/cache_cognitive_metrics',
    HEALTH_METRICS: '@neurolearn/cache_health_metrics',
    SLEEP_ENTRIES: '@neurolearn/cache_sleep_entries',
    BUDGET_ANALYSIS: '@neurolearn/cache_budget_analysis',
    NEUROPLASTICITY_SESSIONS: '@neurolearn/cache_neuroplasticity_sessions',
    SYNAPSE_DATA: '@neurolearn/cache_synapse_data',
  };

  // Keys we keep in hot cache (MMKV) for ultra-fast access
  private static readonly HOT_KEYS = {
    CONTEXT_SNAPSHOT_PREFIX: 'ctx:',
    CONTEXT_CACHE: '@neurolearn/cache_context_snapshots',
  };

  public static getInstance(): HybridStorageService {
    if (!HybridStorageService.instance) {
      HybridStorageService.instance = new HybridStorageService();
    }
    return HybridStorageService.instance;
  }

  /**
   * Initialize hybrid storage service: perform connectivity check and any warmup.
   */
  public async initialize(): Promise<void> {
    try {
      await this.checkConnectivity();
      // Warm up commonly used caches (best-effort)
      try {
        const keys = [HybridStorageService.CACHE_KEYS.SETTINGS, HybridStorageService.CACHE_KEYS.FOCUS_SESSIONS];
        await Promise.all(keys.map(k => AsyncStorage.getItem(k)));
      } catch (e) {
        // ignore warmup failures
      }
    } catch (e) {
      // swallow errors - initialization should be resilient
      console.warn('HybridStorageService.initialize warning:', e);
    }
  }

  /**
   * Shutdown background loops and flush any queued operations if possible.
   */
  public async shutdown(): Promise<void> {
    try {
      // Attempt to flush syncQueue if available (best-effort, cast to any to avoid strict typing on optional helper)
      try { await (syncQueue as any).flush?.(); } catch (_) {}
      // No-op for other parts; background loops will observe state
    } catch (e) {
      console.warn('HybridStorageService.shutdown warning:', e);
    }
  }

  private constructor() {
    this.supabaseService = SupabaseStorageService.getInstance();
    this.checkConnectivity();
    // Start background migration loop for hot->warm->cold promotion
    this.startMigrationLoop();
  }

  // When any local storage reports SQLITE_FULL, set a global cooldown to avoid repeated failing writes.
  private storageUnhealthyUntil: number | null = null;

  // Counters and timers to avoid spamming logs while in cooldown
  private silentSkipAccumulated: number = 0;
  private lastSilentLogAt: number = 0;
  private readonly silentLogIntervalMs: number = 30 * 1000; // how often to emit a progress debug while in cooldown

  // Hard limit on context snapshots to prevent database bloat
  private readonly MAX_CONTEXT_SNAPSHOTS = 100;

  private async checkConnectivity(): Promise<void> {
    try {
      // Simple connectivity check by trying to fetch user settings from Supabase
      await this.supabaseService.getSettings();
      this.isOnline = true;
    } catch (error) {
      console.log('ðŸ”„ Operating in offline mode');
      this.isOnline = false;
    }
  }

  // ==================== GENERIC HYBRID METHODS ====================

  private async hybridGet<T>(
    supabaseMethod: () => Promise<T>,
    cacheKey: string,
    defaultValue: T
  ): Promise<T> {
    // If this is the context snapshot cache we use tiered reads
    if (cacheKey === '@neurolearn/cache_context_snapshots' || cacheKey.startsWith(HybridStorageService.HOT_KEYS.CONTEXT_SNAPSHOT_PREFIX)) {
      try {
        // Try hot (MMKV) first
        if (MMKVStorageService.isAvailable()) {
          // Attempt to get an indexed cache first
          const hotVal = await MMKVStorageService.getObject(cacheKey);
          if (hotVal) return hotVal as T;
        }

        // Then try warm (local DB)
        try {
          const col = database.collections.get('context_snapshots');
          if (col && typeof col.query === 'function') {
            const items: any[] = await col.query().fetch();
            if (items && items.length > 0) {
              const mapped = items.map((rec: any) => {
                try {
                  const raw = rec._raw ?? rec;
                  const payload = raw.payload ? JSON.parse(raw.payload) : raw;
                  const meta = {
                    contextHash: raw.contextHash ?? raw.context_hash ?? payload.contextHash ?? null,
                    version: raw.version ?? payload.version ?? 1,
                    userId: raw.userId ?? raw.user_id ?? payload.userId ?? null,
                    synced: raw.synced ?? false,
                    syncedAt: raw.synced_at ?? raw.syncedAt ?? null,
                    timestamp: raw.timestamp ?? payload.timestamp ?? null,
                  };
                  return { ...payload, ...meta };
                } catch (e) {
                  return rec;
                }
              });
              return mapped as unknown as T;
            }
          }
        } catch (dbErr) {
          // ignore and fall-through to supabase
        }

        // Finally, try cold (Supabase)
        const supabaseData = await supabaseMethod();
        // Cache into warm or hot depending on size/shape
        this.silentCache(cacheKey, supabaseData);
        this.isOnline = true;
        return supabaseData;
      } catch (error) {
        console.warn(`ðŸ“± Tiered read failed for ${cacheKey}:`, error);
        this.isOnline = false;
        return defaultValue;
      }
    }

    // Default behavior for non-context keys: keep Supabase-first fallback to AsyncStorage
    try {
      const supabaseData = await supabaseMethod();
      this.silentCache(cacheKey, supabaseData);
      this.isOnline = true;
      return supabaseData;
    } catch (error) {
      console.warn(`ðŸ“± Supabase unavailable, using cache for ${cacheKey}:`, error);
      this.isOnline = false;

      try {
        const cachedData = await AsyncStorage.getItem(cacheKey);
        if (cachedData) {
          return JSON.parse(cachedData);
        }
      } catch (cacheError) {
        console.error('Cache read failed:', cacheError);
      }

      return defaultValue;
    }
  }

  private async hybridSet<T>(
    supabaseMethod: (data: T) => Promise<void>,
    cacheKey: string,
    data: T
  ): Promise<void> {
    // If this is context snapshot material, route into hot+warm and schedule cold migration
    if (cacheKey === '@neurolearn/cache_context_snapshots' || cacheKey.startsWith(HybridStorageService.HOT_KEYS.CONTEXT_SNAPSHOT_PREFIX)) {
      try {
        // Write to hot tier (fast)
        await this.writeToHot(data as any);
      } catch (e) {
        console.warn('Failed to write to hot tier:', e);
      }

      try {
        // Ensure warm tier has a copy for queryability
        await this.writeToWarm(data as any);
      } catch (e) {
        console.warn('Failed to write to warm tier:', e);
      }

      // Best-effort: queue for cold migration via warm->cold migrator
      try {
        await this.queueForSync(cacheKey, data);
      } catch (e) {
        // ignore
      }

      return;
    }

    // Default behavior for non-context keys
    try {
      await supabaseMethod(data);
      this.isOnline = true;
      await this.silentCache(cacheKey, data);
    } catch (error) {
      console.warn(`ðŸ”„ Supabase save failed, caching locally for ${cacheKey}:`, error);
      this.isOnline = false;
      await this.silentCache(cacheKey, data);
      await this.queueForSync(cacheKey, data);
    }
  }

  private async silentCache<T>(key: string, data: T): Promise<void> {
    // If storage is unhealthy, skip all local cache writes for cooldown period.
    // Aggregate and rate-limit debug messages to avoid log spam.
    if (this.storageUnhealthyUntil && Date.now() < this.storageUnhealthyUntil) {
      this.silentSkipAccumulated = (this.silentSkipAccumulated || 0) + 1;
      const now = Date.now();
      if (!this.lastSilentLogAt || (now - this.lastSilentLogAt) > this.silentLogIntervalMs) {
        const secsLeft = Math.ceil((this.storageUnhealthyUntil - now) / 1000);
        console.debug(`Silent cache skipping writes due to low disk space â€” ${this.silentSkipAccumulated} writes skipped so far. Resuming in ~${secsLeft}s`);
        this.lastSilentLogAt = now;
      }
      return;
    }
    // If a cooldown had just expired, emit a short summary and reset counters.
    if (this.storageUnhealthyUntil && Date.now() >= this.storageUnhealthyUntil) {
      if (this.silentSkipAccumulated > 0) {
        console.info(`Silent cache resumed after cooldown; skipped ${this.silentSkipAccumulated} writes during cooldown.`);
        this.silentSkipAccumulated = 0;
      }
      this.storageUnhealthyUntil = null;
      this.lastSilentLogAt = 0;
    }
    try {
      // Use MMKV for hot cache when available for fast writes
      if (MMKVStorageService.isAvailable() && (key.startsWith(HybridStorageService.HOT_KEYS.CONTEXT_CACHE) || key.startsWith(HybridStorageService.HOT_KEYS.CONTEXT_SNAPSHOT_PREFIX))) {
        try {
          // validate key
          if (typeof key !== 'string' || key.length === 0) throw new Error('invalid key for MMKV');
          await MMKVStorageService.setObject(key, data);
          return;
        } catch (e) {
          const msg = String((e as any)?.message || e || '');
          console.warn('MMKV setObject in silentCache failed:', e);
          if (msg.includes('SQLITE_FULL') || msg.toLowerCase().includes('database or disk is full')) {
            try { (MMKVStorageService as any).markUnhealthy?.(); } catch(_) {}
            // Set global unhealthy flag for 5 minutes (only if not already in cooldown)
            if (!this.storageUnhealthyUntil || Date.now() >= this.storageUnhealthyUntil) {
              this.storageUnhealthyUntil = Date.now() + (5 * 60 * 1000);
              this.silentSkipAccumulated = 0;
              this.lastSilentLogAt = 0;
              console.warn('Global storage entered cooldown due to SQLITE_FULL; will skip all local cache writes for 5 minutes');
            }
            return;
          }
          // fallthrough to AsyncStorage
        }
      }

      // Warm-tier writes (if it's context snapshots and DB available) are handled elsewhere; default to AsyncStorage for other cache keys
      try {
        await AsyncStorage.setItem(key, JSON.stringify(data));
      } catch (error) {
        const msg = String((error as any)?.message || error || '');
        if (msg.includes('SQLITE_FULL') || msg.toLowerCase().includes('database or disk is full')) {
          this.storageUnhealthyUntil = Date.now() + (5 * 60 * 1000);
          console.warn('Global storage entered cooldown due to SQLITE_FULL; will skip all local cache writes for 5 minutes');
          return;
        }
        throw error;
      }
    } catch (error) {
      console.error('Silent cache failed:', error);
      // Don't throw - caching is optional
    }
  }

  private async queueForSync<T>(key: string, data: T): Promise<void> {
    try {
      await syncQueue.enqueue(key, data);
      // Best-effort immediate sync
      this.backgroundSync().catch(() => {});
    } catch (error) {
      console.error('Failed to queue sync via syncQueue helper:', error);
    }
  }

  /**
   * Return a best-effort estimate of storage size for warm tier (AsyncStorage + index)
   */
  public async getStorageSize(): Promise<number> {
    try {
      const keys = await AsyncStorage.getAllKeys();
      let size = 0;
      const items = await Promise.all(keys.map(k => AsyncStorage.getItem(k)));
      for (const v of items) {
        if (v) size += v.length * 2; // rough estimate
      }
      return size;
    } catch (e) {
      return 0;
    }
  }

  // ==================== THREE-TIER HELPERS ====================
  private HOT_TTL_MS = 48 * 60 * 60 * 1000; // 48 hours
  private WARM_TTL_MS = 30 * 24 * 60 * 60 * 1000; // 30 days

  private async writeToHot(snapshot: any): Promise<void> {
    try {
      const key = `${HybridStorageService.HOT_KEYS.CONTEXT_SNAPSHOT_PREFIX}${snapshot.contextHash || snapshot.id || Date.now()}`;
      await MMKVStorageService.setObject(key, snapshot);

      // Maintain index of hot keys for migration scanning
      const indexKey = '@neurolearn/hot_index';
      let idx: any = await MMKVStorageService.getObject(indexKey);
      if (!Array.isArray(idx)) idx = [];
      try {
        if (!idx.includes(key)) {
          idx.push(key);
          await MMKVStorageService.setObject(indexKey, idx);
        }
      } catch (e) {
        // Defensive: if includes or push fails because idx is malformed, rebuild index
        try {
          const keys = await MMKVStorageService.getKeysWithPrefix(HybridStorageService.HOT_KEYS.CONTEXT_SNAPSHOT_PREFIX);
          const rebuilt = Array.isArray(keys) ? keys : [];
          if (!rebuilt.includes(key)) rebuilt.push(key);
          await MMKVStorageService.setObject(indexKey, rebuilt);
        } catch (inner) {
          // If MMKV is failing due to SQLITE_FULL or similar, escalate to mark unhealthy
          const msg = String((inner as any)?.message || inner || '');
          console.warn('Failed to update hot index, marking MMKV unhealthy:', inner);
          try {
            // mark MMKV unhealthy via exported instance method
            (MMKVStorageService as any).markUnhealthy?.();
          } catch (mErr) {
            // ignore
          }
        }
      }
    } catch (e) {
      // If underlying storage reports disk full, attempt to mark MMKV as unhealthy
      const msg = String((e as any)?.message || e || '');
      console.warn('writeToHot failed:', e);
      if (msg.includes('SQLITE_FULL') || msg.toLowerCase().includes('database or disk is full')) {
        try {
          (MMKVStorageService as any).markUnhealthy?.();
        } catch (mErr) {
          // ignore
        }
      }
      throw e;
    }
  }

  private async writeToWarm(snapshot: any): Promise<void> {
    try {
      // If warm DB is in cooldown due to previous SQLITE_FULL, skip warm writes.
      // If global storage is unhealthy, skip warm DB writes for cooldown period
      if (this.storageUnhealthyUntil && Date.now() < this.storageUnhealthyUntil) {
        console.debug('Warm DB write skipped due to disk full cooldown');
        // Best-effort: persist a minimal pointer into AsyncStorage-based fallback
        try {
          const dbKey = 'db:context_snapshots';
          const raw = await AsyncStorage.getItem(dbKey);
          let arr: any[] = [];
          try { arr = raw ? JSON.parse(raw) : []; if (!Array.isArray(arr)) arr = []; } catch { arr = []; }
          const rec = { id: `local_${Date.now()}`, timestamp: Date.now(), payload: JSON.stringify(snapshot), contextHash: snapshot.contextHash || null, synced: false };
          arr.push(rec);
          // Trim to last 200 entries to avoid runaway growth
          if (arr.length > 200) arr = arr.slice(-200);
          await AsyncStorage.setItem(dbKey, JSON.stringify(arr));
        } catch (e) {
          // ignore
        }
        return;
      }
      // Use a merge strategy to handle concurrent updates and tombstones.
      await database.write(async () => {
        const col = database.collections.get('context_snapshots');

        // Enforce hard limit on context snapshots to prevent database bloat
        let allRecords: any[] = [];
        try {
          const q = col.query ? col.query() : null;
          if (q && typeof q.fetch === 'function') {
            allRecords = await q.fetch();
          } else if (typeof col.fetch === 'function') {
            allRecords = await col.fetch();
          }
        } catch (e) {
          allRecords = [];
        }
        if (allRecords.length >= this.MAX_CONTEXT_SNAPSHOTS) {
          // Sort by timestamp ascending (oldest first)
          allRecords.sort((a, b) => {
            const aTs = (a._raw ?? a).timestamp ?? (a._raw ?? a).created_at ?? 0;
            const bTs = (b._raw ?? b).timestamp ?? (b._raw ?? b).created_at ?? 0;
            return aTs - bTs;
          });
          const toDeleteCount = allRecords.length - this.MAX_CONTEXT_SNAPSHOTS + 1; // +1 to make room for new
          const toDelete = allRecords.slice(0, toDeleteCount);
          for (const rec of toDelete) {
            try {
              if (typeof rec.delete === 'function') {
                await rec.delete();
              } else if (typeof rec.destroy === 'function') {
                await rec.destroy();
              } else if (rec.id && typeof (col as any).removeById === 'function') {
                await (col as any).removeById(rec.id);
              }
            } catch (e) {
              console.warn('Failed to delete old context snapshot:', e);
            }
          }
        }

        // Try to find existing by contextHash
        let existing: any[] = [];
        try {
          const q = col.query ? col.query() : null;
          if (q && typeof q.fetch === 'function') existing = await q.fetch();
          else if (typeof col.fetch === 'function') existing = await col.fetch();
        } catch (e) {
          existing = [];
        }

        const contextHash = snapshot.contextHash || snapshot.id || null;
        const found = existing.find((rec: any) => {
          const raw = rec._raw ?? rec;
          return raw && (raw.contextHash === contextHash || raw.context_hash === contextHash) || (rec && rec.contextHash === contextHash);
        });

        // Helper to merge payloads deterministically
        const mergePayload = (oldPayload: any, newPayload: any) => {
          try {
            const a = typeof oldPayload === 'string' ? JSON.parse(oldPayload) : (oldPayload || {});
            const b = typeof newPayload === 'string' ? JSON.parse(newPayload) : (newPayload || {});
            // Shallow merge: prefer non-null fields from newer payload, then fall back to older
            const merged = { ...a, ...b };
            return JSON.stringify(merged);
          } catch (e) {
            return JSON.stringify(newPayload || oldPayload || {});
          }
        };

        if (found && typeof found.update === 'function') {
          // Conflict resolution: if incoming version is newer, replace/merge; if equal, merge by timestamp; if older, ignore
          await found.update((r: any) => {
            const incomingVersion = snapshot.version || 1;
            const existingVersion = r.version || 1;
            const incomingTs = snapshot.timestamp || Date.now();
            const existingTs = r.timestamp || r.updated_at || Date.now();

            // Tombstone handling: if snapshot has deleted flag, mark as deleted/tombstone
            if (snapshot.deleted) {
              r.deleted = true;
              r.deleted_at = Date.now();
              r.synced = false;
              r.updated_at = Date.now();
              r.payload = mergePayload(r.payload, snapshot);
              return;
            }

            if (incomingVersion > existingVersion) {
              r.payload = mergePayload(r.payload, snapshot);
              r.version = incomingVersion;
              r.timestamp = incomingTs;
              r.userId = snapshot.userId || r.userId || null;
              r.synced = false;
              r.updated_at = Date.now();
            } else if (incomingVersion === existingVersion) {
              // Tie-breaker: use latest timestamp
              if (incomingTs >= existingTs) {
                r.payload = mergePayload(r.payload, snapshot);
                r.timestamp = incomingTs;
                r.synced = false;
                r.updated_at = Date.now();
              }
              // else keep existing
            } else {
              // incoming is older - ignore to avoid overwriting newer local changes
            }
          });
        } else if (typeof col.create === 'function') {
          await col.create((r: any) => {
            r.timestamp = snapshot.timestamp || Date.now();
            r.sessionId = snapshot.sessionId || null;
            r.payload = JSON.stringify(snapshot);
            r.contextHash = contextHash;
            r.version = snapshot.version || 1;
            r.userId = snapshot.userId || null;
            r.synced = false;
            r.synced_at = null;
            r.created_at = Date.now();
            r.updated_at = Date.now();
          });
        } else if (typeof (col as any).insert === 'function') {
          // Fallback to insert-like API
          await (col as any).insert({
            timestamp: snapshot.timestamp || Date.now(),
            sessionId: snapshot.sessionId || null,
            payload: JSON.stringify(snapshot),
            contextHash: contextHash,
            version: snapshot.version || 1,
            userId: snapshot.userId || null,
            synced: false,
            synced_at: null,
            created_at: Date.now(),
            updated_at: Date.now(),
          });
        }
      });
    } catch (e) {
      console.warn('writeToWarm failed:', e);
      throw e;
    }
  }

  private async writeToCold(snapshot: any): Promise<void> {
    try {
      await this.supabaseService.saveContextSnapshot(snapshot);
    } catch (e) {
      console.warn('writeToCold failed:', e);
      throw e;
    }
  }

  private async migrateHotToWarm(): Promise<{ migrated: number }> {
    try {
      if (!MMKVStorageService.isAvailable()) return { migrated: 0 };
      const indexKey = '@neurolearn/hot_index';
      const keys: string[] = (await MMKVStorageService.getObject(indexKey)) || [];
      const now = Date.now();
      let migrated = 0;
      for (const key of keys.slice()) {
        try {
          const item = await MMKVStorageService.getObject(key);
          if (!item) {
            // remove missing key from index
            const newIdx = (await MMKVStorageService.getObject(indexKey)) || [];
            const filtered = newIdx.filter((k: string) => k !== key);
            await MMKVStorageService.setObject(indexKey, filtered);
            continue;
          }
          const ts = item.timestamp || item.created_at || item.createdAt || now;
          if (now - ts > this.HOT_TTL_MS) {
            await this.writeToWarm(item);
            await MMKVStorageService.removeItem(key);
            const newIdx = (await MMKVStorageService.getObject(indexKey)) || [];
            const filtered = newIdx.filter((k: string) => k !== key);
            await MMKVStorageService.setObject(indexKey, filtered);
            migrated++;
          }
        } catch (e) {
          console.warn('migrateHotToWarm: item migration failed for', key, e);
          this.migrationMetrics.errors.push({ phase: 'hotToWarm', id: key, error: e, at: Date.now() });
        }
      }
      // update metrics
      this.migrationMetrics.hotToWarm += migrated;
      this.migrationMetrics.lastRunAt = Date.now();
      return { migrated };
    } catch (e) {
      console.warn('migrateHotToWarm failed:', e);
      this.migrationMetrics.errors.push({ phase: 'hotToWarm', error: e, at: Date.now() });
      return { migrated: 0 };
    }
  }

  private async migrateWarmToCold(): Promise<{ migrated: number }> {
    try {
      const col = database.collections.get('context_snapshots');
      if (!col) return { migrated: 0 };
      // Fetch all records that are not synced and older than WARM_TTL_MS
      let all: any[] = [];
      try {
        const q = col.query ? col.query() : null;
        if (q && typeof q.fetch === 'function') {
          all = await q.fetch();
        } else if (typeof col.fetch === 'function') {
          all = await col.fetch();
        }
      } catch (e) {
        // fallback: try to read directly
        all = [];
      }

      const now = Date.now();
      let migrated = 0;
      const candidates = all.filter((rec: any) => {
        const raw = rec._raw ?? rec;
        const ts = raw.timestamp ?? raw.created_at ?? raw.createdAt ?? now;
        const synced = raw.synced ?? false;
        return !synced && (now - ts > this.WARM_TTL_MS);
      });

      if (candidates.length === 0) {
        this.migrationMetrics.lastRunAt = Date.now();
        return { migrated: 0 };
      }

      // Prepare payloads for batch upload
      const snapshots: any[] = candidates.map((rec: any) => {
        const raw = rec._raw ?? rec;
        const payload = raw.payload ? (typeof raw.payload === 'string' ? JSON.parse(raw.payload) : raw.payload) : raw;
        // normalize shape
        return {
          id: raw.id || payload.id || undefined,
          sessionId: payload.sessionId || payload.session_id || null,
          timestamp: payload.timestamp || payload.created_at || Date.now(),
          contextHash: payload.contextHash || payload.context_hash || null,
          version: payload.version || payload.v || 1,
          userId: payload.userId || payload.user_id || null,
          ...payload,
        };
      });

      try {
        const batchSize = (STORAGE_CONFIG && STORAGE_CONFIG.cold && STORAGE_CONFIG.cold.batchSize) || 50;
        const compression = (STORAGE_CONFIG && STORAGE_CONFIG.cold && STORAGE_CONFIG.cold.compression) || false;
        // Upload in chunks
        for (let i = 0; i < snapshots.length; i += batchSize) {
          const chunk = snapshots.slice(i, i + batchSize);
          try {
            await this.supabaseService.saveContextSnapshotsBatch(chunk, { compression, batchSize });
            // mark records in this chunk as synced
            const chunkHashes = chunk.map((s: any) => s.contextHash).filter(Boolean);
            if (chunkHashes.length > 0) await this.markContextSnapshotsSynced(chunkHashes);
            migrated += chunk.length;
          } catch (batchErr) {
            // If batch fails, fallback to per-record upload to capture errors and continue
            for (const s of chunk) {
              try {
                await this.writeToCold(s);
                if (s.contextHash) await this.markContextSnapshotsSynced([s.contextHash]);
                migrated++;
              } catch (e) {
                this.migrationMetrics.errors.push({ phase: 'warmToCold', id: s.contextHash || s.id, error: e, at: Date.now() });
              }
            }
          }
        }
      } catch (e) {
        this.migrationMetrics.errors.push({ phase: 'warmToCold', error: e, at: Date.now() });
      }
      // update metrics
      this.migrationMetrics.warmToCold += migrated;
      this.migrationMetrics.lastRunAt = Date.now();
      return { migrated };
    } catch (e) {
      console.warn('migrateWarmToCold failed:', e);
      this.migrationMetrics.errors.push({ phase: 'warmToCold', error: e, at: Date.now() });
      return { migrated: 0 };
    }
  }

  private migrationIntervalId: any = null;

  // Migration metrics and tracing
  private migrationMetrics: {
    lastRunAt: number | null;
    hotToWarm: number;
    warmToCold: number;
    errors: Array<{ phase: string; id?: string; error: any; at: number }>;
  } = {
    lastRunAt: null,
    hotToWarm: 0,
    warmToCold: 0,
    errors: [],
  };

  // Cleanup metrics
  private cleanupMetrics: {
    lastRunAt: number | null;
    cleanedHot: number;
    cleanedWarm: number;
    errors: Array<{ phase: string; id?: string; error: any; at: number }>;
  } = {
    lastRunAt: null,
    cleanedHot: 0,
    cleanedWarm: 0,
    errors: [],
  };

  // Telemetry sink(s) - optional callbacks that receive metrics after each migration/cleanup run
  private telemetrySinks: Array<(metrics: any) => void> = [];

  // Configurable retention and batching
  private CLEANUP_BATCH_SIZE = 100;
  private HOT_MAX_ITEMS = 1000;
  private WARM_RETENTION_MS = 90 * 24 * 60 * 60 * 1000; // 90 days default

  public getMigrationMetrics() {
    return { ...this.migrationMetrics };
  }

  public getCleanupMetrics() {
    return { ...this.cleanupMetrics };
  }

  /**
   * Configure retention and cleanup parameters at runtime.
   */
  public configureRetention(opts: {
    hotTtlMs?: number;
    warmTtlMs?: number;
    warmRetentionMs?: number;
    hotMaxItems?: number;
    cleanupBatchSize?: number;
    migrationIntervalMs?: number;
  }) {
    if (typeof opts.hotTtlMs === 'number') this.HOT_TTL_MS = opts.hotTtlMs;
    if (typeof opts.warmTtlMs === 'number') this.WARM_TTL_MS = opts.warmTtlMs;
    if (typeof opts.warmRetentionMs === 'number') this.WARM_RETENTION_MS = opts.warmRetentionMs;
    if (typeof opts.hotMaxItems === 'number') this.HOT_MAX_ITEMS = opts.hotMaxItems;
    if (typeof opts.cleanupBatchSize === 'number') this.CLEANUP_BATCH_SIZE = opts.cleanupBatchSize;
    if (typeof opts.migrationIntervalMs === 'number') {
      try {
        if (this.migrationIntervalId) clearInterval(this.migrationIntervalId);
      } catch (e) {}
      // restart loop with new interval
      this.migrationIntervalId = setInterval(() => {
        (async () => {
          await this.migrateHotToWarm();
          await this.migrateWarmToCold();
          await this.cleanupHotStorage();
          await this.cleanupWarmStorage();
          this.emitTelemetry();
        })().catch(() => {});
      }, opts.migrationIntervalMs);
    }
  }

  /** Register a telemetry sink callback that will receive run metrics. */
  public registerTelemetrySink(cb: (metrics: any) => void) {
    if (typeof cb === 'function') this.telemetrySinks.push(cb);
  }

  /** Stop the background migration loop if running. Useful for tests and app teardown. */
  public stopMigrationLoop(): void {
    try {
      if (this.migrationIntervalId) {
        clearInterval(this.migrationIntervalId);
        this.migrationIntervalId = null;
      }
    } catch (e) {
      // ignore
    }
  }

  /** Dispose the service and stop any background work. */
  public dispose(): void {
    try {
      this.stopMigrationLoop();
      // Clear telemetry sinks
      this.telemetrySinks = [];
      console.log('ðŸ§¹ HybridStorageService disposed');
    } catch (e) {
      // ignore
    }
  }

  private emitTelemetry() {
    const metrics = {
      migration: { ...this.migrationMetrics },
      cleanup: { ...this.cleanupMetrics },
      timestamp: Date.now(),
    };
    try {
      for (const s of this.telemetrySinks) {
        try { s(metrics); } catch (e) { /* swallow sink errors */ }
      }
    } catch (e) {
      // ignore
    }
  }

  private startMigrationLoop(): void {
    // Run migration every 15 minutes
    try {
      if (this.migrationIntervalId) return;
      const run = async () => {
        await this.migrateHotToWarm();
        await this.migrateWarmToCold();
        // Run cleanup after migrations
        await this.cleanupHotStorage();
        await this.cleanupWarmStorage();
        // Emit telemetry if any sink registered
        this.emitTelemetry();
      };
      // start immediately then schedule
      run().catch(() => {});
      this.migrationIntervalId = setInterval(() => run().catch(() => {}), 15 * 60 * 1000);
    } catch (e) {
      // ignore
    }
  }

  /**
   * Cleanup hot storage (MMKV) to enforce TTL and max-items limits.
   */
  private async cleanupHotStorage(): Promise<{ cleaned: number }> {

    try {
      const indexKey = '@neurolearn/hot_index';
      const now = Date.now();
      let cleaned = 0;

      // If MMKV is unavailable (tests/CI), operate against AsyncStorage fallback
      if (!MMKVStorageService.isAvailable()) {
        try {
          const raw = await AsyncStorage.getItem(indexKey);
          let keys: string[] = raw ? JSON.parse(raw) : [];
          if (!Array.isArray(keys)) keys = [];

          const survivors: string[] = [];
          for (const key of keys) {
            try {
              const itemRaw = await AsyncStorage.getItem(key);
              if (!itemRaw) {
                cleaned++;
                continue;
              }
              const item = JSON.parse(itemRaw);
              const ts = item.timestamp || item.created_at || item.createdAt || now;
              if (now - ts > this.HOT_TTL_MS) {
                await AsyncStorage.removeItem(key);
                cleaned++;
              } else {
                survivors.push(key);
              }
            } catch (e) {
              this.cleanupMetrics.errors.push({ phase: 'cleanupHot', id: key, error: e, at: Date.now() });
            }
          }

          try {
            await AsyncStorage.setItem(indexKey, JSON.stringify(survivors));
          } catch (e) {
            // ignore
          }

          this.cleanupMetrics.cleanedHot += cleaned;
          this.cleanupMetrics.lastRunAt = Date.now();
          return { cleaned };
        } catch (e) {
          this.cleanupMetrics.errors.push({ phase: 'cleanupHot', error: e, at: Date.now() });
          return { cleaned: 0 };
        }
      }

      let keys: string[] = (await MMKVStorageService.getObject(indexKey)) || [];
      if (!Array.isArray(keys)) keys = [];
      let cleanedLocal = 0;

      // Remove expired by TTL first
      const survivors: string[] = [];
      for (const key of keys) {
        try {
          const item = await MMKVStorageService.getObject(key);
          if (!item) {
            cleanedLocal++; // missing -> count as cleaned
            continue;
          }
          const ts = item.timestamp || item.created_at || item.createdAt || now;
          if (now - ts > this.HOT_TTL_MS) {
            await MMKVStorageService.removeItem(key);
            cleanedLocal++;
          } else {
            survivors.push(key);
          }
        } catch (e) {
          this.cleanupMetrics.errors.push({ phase: 'cleanupHot', id: key, error: e, at: Date.now() });
        }
      }

      // Enforce max items by dropping oldest beyond HOT_MAX_ITEMS
      if (survivors.length > this.HOT_MAX_ITEMS) {
        // Load timestamps for survivors (limited batch)
        const pairs: Array<{ key: string; ts: number }> = [];
        for (const k of survivors) {
          try {
            const it = await MMKVStorageService.getObject(k);
            const ts = it?.timestamp || it?.created_at || it?.createdAt || now;
            pairs.push({ key: k, ts });
          } catch (e) {
            pairs.push({ key: k, ts: now });
          }
        }
        pairs.sort((a,b) => a.ts - b.ts); // oldest first
        const toDrop = pairs.slice(0, pairs.length - this.HOT_MAX_ITEMS);
        for (const d of toDrop) {
          try {
            await MMKVStorageService.removeItem(d.key);
            cleaned++;
          } catch (e) {
            this.cleanupMetrics.errors.push({ phase: 'cleanupHot', id: d.key, error: e, at: Date.now() });
          }
        }
        // rebuild survivors after drop
        survivors.splice(0, survivors.length - this.HOT_MAX_ITEMS);
      }

      // Enforce byte-size limit (if configured) by estimating sizes and dropping oldest until under limit
      try {
        const maxBytes = (STORAGE_CONFIG && STORAGE_CONFIG.hot && STORAGE_CONFIG.hot.maxSize) || (10 * 1024 * 1024);
        // Get sizes for survivor keys
        if (survivors.length > 0 && typeof MMKVStorageService.estimateSizeForKeys === 'function') {
          const sizes = await MMKVStorageService.estimateSizeForKeys(survivors);
          let totalBytes = sizes || 0;
          // If above max, drop oldest entries until under limit
          if (totalBytes > maxBytes) {
            // Build key->size map by fetching individual sizes as fallback
            const keySizes: Array<{ key: string; size: number; ts: number }> = [];
            for (const k of survivors) {
              try {
                const v = await MMKVStorageService.getObject(k);
                const ts = v?.timestamp || v?.created_at || v?.createdAt || now;
                const raw = await MMKVStorageService.getItem(k);
                const size = raw ? (raw.length * 2) : 0;
                keySizes.push({ key: k, size, ts });
              } catch (e) {
                keySizes.push({ key: k, size: 0, ts: now });
              }
            }
            keySizes.sort((a,b) => a.ts - b.ts); // oldest first
            for (const entry of keySizes) {
              if (totalBytes <= maxBytes) break;
              try {
                await MMKVStorageService.removeItem(entry.key);
                totalBytes -= entry.size;
                cleaned++;
              } catch (e) {
                this.cleanupMetrics.errors.push({ phase: 'cleanupHot', id: entry.key, error: e, at: Date.now() });
              }
            }
          }
        }
      } catch (e) {
        // ignore size enforcement errors
        this.cleanupMetrics.errors.push({ phase: 'cleanupHot', error: e, at: Date.now() });
      }

      // Persist updated index of survivors
      try {
        await MMKVStorageService.setObject(indexKey, survivors);
      } catch (e) {
        // ignore
      }

      this.cleanupMetrics.cleanedHot += (cleanedLocal || cleaned);
      this.cleanupMetrics.lastRunAt = Date.now();
      return { cleaned: (cleanedLocal || cleaned) };
    } catch (e) {
      this.cleanupMetrics.errors.push({ phase: 'cleanupHot', error: e, at: Date.now() });
      return { cleaned: 0 };
    }
  }

  /**
   * Cleanup warm DB storage by removing old synced records beyond warm retention window.
   */
  private async cleanupWarmStorage(): Promise<{ cleaned: number }> {
    try {
      const col = database.collections.get('context_snapshots');
      if (!col) return { cleaned: 0 };
      let all: any[] = [];
      try {
        const q = col.query ? col.query() : null;
        if (q && typeof q.fetch === 'function') all = await q.fetch();
        else if (typeof col.fetch === 'function') all = await col.fetch();
      } catch (e) {
        all = [];
      }

      const now = Date.now();
      let cleaned = 0;
      const toDelete: any[] = [];

      for (const rec of all) {
        try {
          const raw = rec._raw ?? rec;
          const ts = raw.timestamp ?? raw.created_at ?? raw.createdAt ?? now;
          const synced = raw.synced ?? false;
          if (synced && (now - ts > this.WARM_RETENTION_MS)) {
            toDelete.push({ rec, id: raw?.id || rec.id });
          }
        } catch (e) {
          this.cleanupMetrics.errors.push({ phase: 'cleanupWarm', error: e, at: Date.now() });
        }
      }

      // Perform deletions in batches
      const batches = Math.ceil(toDelete.length / this.CLEANUP_BATCH_SIZE) || 0;
      for (let i = 0; i < batches; i++) {
        const batch = toDelete.slice(i * this.CLEANUP_BATCH_SIZE, (i + 1) * this.CLEANUP_BATCH_SIZE);
        for (const item of batch) {
          const rec = item.rec;
          const id = item.id;
          try {
            // Prefer collection-level delete/update API
            if (id && typeof (col as any).removeById === 'function') {
              await (col as any).removeById(id);
              cleaned++;
              continue;
            }
            if (typeof rec.delete === 'function') {
              await rec.delete();
              cleaned++;
              continue;
            }
            if (typeof rec.destroy === 'function') {
              await rec.destroy();
              cleaned++;
              continue;
            }
            // Fallback: mark as deleted flag and persist via writeAll if available
            try {
              const rawFallback = rec._raw ?? rec;
              rawFallback.deleted = true;
              if (typeof (col as any).writeAll === 'function') {
                await (col as any).writeAll(all.map((r: any) => (r._raw ?? r)));
                cleaned++;
                continue;
              }
            } catch (e) {
              this.cleanupMetrics.errors.push({ phase: 'cleanupWarm', id, error: e, at: Date.now() });
            }
          } catch (e) {
            this.cleanupMetrics.errors.push({ phase: 'cleanupWarm', id, error: e, at: Date.now() });
          }
        }
      }

      this.cleanupMetrics.cleanedWarm += cleaned;
      this.cleanupMetrics.lastRunAt = Date.now();
      return { cleaned };
    } catch (e) {
      this.cleanupMetrics.errors.push({ phase: 'cleanupWarm', error: e, at: Date.now() });
      return { cleaned: 0 };
    }
  }

  public async backgroundSync(): Promise<{ synced: number; failed: number }> {
    if (!this.isOnline) {
      await this.checkConnectivity();
      if (!this.isOnline) return { synced: 0, failed: 0 };
    }

    try {
      const { dbItems, legacyItems } = await syncQueue.fetchAll();

      if (dbItems.length === 0 && legacyItems.length === 0) return { synced: 0, failed: 0 };

      let synced = 0;
      let failed = 0;
      const remainingLegacy: any[] = [];

      // Process DB items first
      for (const rec of dbItems) {
        try {
          await this.syncItemToSupabase({ key: rec.key, data: rec.data });
          await syncQueue.removeDbRecord(rec.record);
          synced++;
        } catch (err) {
          failed++;
          // bump attempts
          await syncQueue.incrementDbAttempt(rec.record);
        }
      }
      // Process legacy async items
      for (const item of legacyItems) {
        try {
          await this.syncItemToSupabase(item);
          synced++;
        } catch (err) {
          failed++;
          // Keep a copy to persist back into legacy queue for retry
          try {
            remainingLegacy.push(item);
          } catch (e) {
            // ignore
          }
        }
      }

  // Persist remaining legacy items
  await syncQueue.persistLegacyQueue(remainingLegacy);

      if (synced > 0) {
        console.log(`âœ… Background sync completed: ${synced} synced, ${failed} failed`);
      }

      return { synced, failed };
    } catch (error) {
      console.error('Background sync error:', error);
      return { synced: 0, failed: 0 };
    }
  }

  private async syncItemToSupabase(item: any): Promise<void> {
    // Handle context snapshots explicitly
    if (item.key === HybridStorageService.HOT_KEYS.CONTEXT_CACHE || item.key === '@neurolearn/cache_context_snapshots') {
      // item.data may be a single snapshot or an array
      const snapshots = Array.isArray(item.data) ? item.data : [item.data];
      for (const s of snapshots) {
        // Ensure version is present before sending
        s.version = s.version || 1;
        try {
          await this.supabaseService.saveContextSnapshot(s);
          // Mark local warm DB as synced if it exists
          if (s.contextHash) await this.markContextSnapshotsSynced([s.contextHash]);
        } catch (err) {
          console.error('Failed to sync context snapshot to Supabase:', err);
          throw err;
        }
      }
      return;
    }
    switch (item.key) {
      case HybridStorageService.CACHE_KEYS.FLASHCARDS:
        await this.supabaseService.saveFlashcards(item.data);
        break;
      case HybridStorageService.CACHE_KEYS.LOGIC_NODES:
        await this.supabaseService.saveLogicNodes(item.data);
        break;
      case HybridStorageService.CACHE_KEYS.FOCUS_SESSIONS:
        await this.supabaseService.saveFocusSessions(item.data);
        break;
      case HybridStorageService.CACHE_KEYS.READING_SESSIONS:
        await this.supabaseService.saveReadingSessions(item.data);
        break;
      case HybridStorageService.CACHE_KEYS.SETTINGS:
        await this.supabaseService.saveSettings(item.data);
        break;
      case HybridStorageService.CACHE_KEYS.SOURCE_LINKS:
        await this.supabaseService.saveSourceLinks(item.data);
        break;
      case HybridStorageService.CACHE_KEYS.COGNITIVE_METRICS:
        await this.supabaseService.saveCognitiveMetrics(item.data.userId, item.data);
        break;
      case HybridStorageService.CACHE_KEYS.HEALTH_METRICS:
        await this.supabaseService.saveHealthMetrics(item.data.userId, item.data);
        break;
      case HybridStorageService.CACHE_KEYS.SLEEP_ENTRIES:
        await this.supabaseService.saveSleepEntries(item.data.userId, item.data);
        break;
      case HybridStorageService.CACHE_KEYS.BUDGET_ANALYSIS:
        await this.supabaseService.saveBudgetAnalysis(item.data.userId, item.data);
        break;
      default:
        console.warn('Unknown sync item type:', item.key);
    }
  }

  async getTasks(): Promise<Task[]> {
    const raw = await this.hybridGet(
      () => this.supabaseService.getTasks(),
      HybridStorageService.CACHE_KEYS.TASKS,
      []
    );

    // Validate and sanitize tasks
    try {
      const validated: Task[] = (raw as any[])
        .map((t) => validateTask(t))
        .filter((v) => v !== null) as Task[];
      return validated;
    } catch (e) {
      console.warn('Task validation pipeline failed, returning raw data', e);
      return raw as Task[];
    }
  }

  async saveTasks(tasks: Task[]): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveTasks(data),
      HybridStorageService.CACHE_KEYS.TASKS,
      tasks
    );
  }

  async getMemoryPalaces(): Promise<MemoryPalace[]> {
    const raw = await this.hybridGet(
      () => this.supabaseService.getMemoryPalaces(),
      HybridStorageService.CACHE_KEYS.MEMORY_PALACES,
      []
    );

    try {
      const validated: MemoryPalace[] = (raw as any[])
        .map((p) => validateMemoryPalace(p))
        .filter((v) => v !== null) as MemoryPalace[];
      return validated;
    } catch (e) {
      console.warn('MemoryPalace validation pipeline failed, returning raw data', e);
      return raw as MemoryPalace[];
    }
  }

  async saveMemoryPalaces(palaces: MemoryPalace[]): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveMemoryPalaces(data),
      HybridStorageService.CACHE_KEYS.MEMORY_PALACES,
      palaces
    );
  }

  async getCognitiveMetrics(userId: string): Promise<any[]> {
    return this.hybridGet(
      () => this.supabaseService.getCognitiveMetrics(userId),
      HybridStorageService.CACHE_KEYS.COGNITIVE_METRICS,
      []
    );
  }

  async saveCognitiveMetrics(userId: string, metrics: any[]): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveCognitiveMetrics(userId, data),
      HybridStorageService.CACHE_KEYS.COGNITIVE_METRICS,
      metrics
    );
  }

  async getHealthMetrics(userId: string): Promise<any> {
    return this.hybridGet(
      () => this.supabaseService.getHealthMetrics(userId),
      HybridStorageService.CACHE_KEYS.HEALTH_METRICS,
      {
        userId,
        date: new Date().toISOString().split('T')[0],
        sleepHours: 8,
        sleepQuality: 7,
        workoutIntensity: 5,
        stressLevel: 3,
        heartRateAvg: 70,
        steps: 8000,
        caloriesBurned: 2000,
        recoveryScore: 8,
      }
    );
  }

  async saveHealthMetrics(userId: string, metrics: any): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveHealthMetrics(userId, data),
      HybridStorageService.CACHE_KEYS.HEALTH_METRICS,
      metrics
    );
  }

  // ==================== SETTINGS ====================

  async getSettings(): Promise<Settings> {
    return this.hybridGet(
      () => this.supabaseService.getSettings(),
      HybridStorageService.CACHE_KEYS.SETTINGS,
      {
        theme: 'dark',
        dailyGoal: 60,
        defaultSession: 'pomodoro',
        todoistToken: '',
        notionToken: '',
        autoSync: true,
        notifications: {
          studyReminders: true,
          breakAlerts: true,
          reviewNotifications: true,
        },
      } as Settings
    );
  }

  async saveSettings(settings: Settings): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveSettings(data),
      HybridStorageService.CACHE_KEYS.SETTINGS,
      settings
    );
  }

  // ==================== FLASHCARDS ====================

  async getFlashcards(): Promise<(Flashcard | Flashcard)[]> {
    return this.hybridGet(
      () => this.supabaseService.getFlashcards(),
      HybridStorageService.CACHE_KEYS.FLASHCARDS,
      []
    );
  }

  async saveFlashcards(flashcards: (Flashcard | Flashcard)[]): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveFlashcards(data),
      HybridStorageService.CACHE_KEYS.FLASHCARDS,
      flashcards
    );
  }

  // ==================== LOGIC NODES ====================

  async getLogicNodes(): Promise<LogicNode[]> {
    return this.hybridGet(
      () => this.supabaseService.getLogicNodes(),
      HybridStorageService.CACHE_KEYS.LOGIC_NODES,
      []
    );
  }

  async saveLogicNodes(nodes: LogicNode[]): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveLogicNodes(data),
      HybridStorageService.CACHE_KEYS.LOGIC_NODES,
      nodes
    );
  }

  async addLogicNode(nodeData: Partial<LogicNode>): Promise<LogicNode> {
    try {
      // Try Supabase first
      const newNode = await this.supabaseService.addLogicNode(nodeData);

      // Update cache
      const currentNodes = await this.getLogicNodes();
      await this.silentCache(HybridStorageService.CACHE_KEYS.LOGIC_NODES, [...currentNodes, newNode]);

      return newNode;
    } catch (error) {
      console.warn('ðŸ”„ Creating logic node offline');

      // Fallback: Create locally and queue for sync
      const now = new Date();
      const newNode: LogicNode = {
        id: `logic_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        question: nodeData.question || '',
        premise1: nodeData.premise1 || '',
        premise2: nodeData.premise2 || '',
        conclusion: nodeData.conclusion || '',
        type: nodeData.type || 'deductive',
        domain: nodeData.domain || 'general',
        difficulty: nodeData.difficulty || 3,
        easeFactor: 2.5,
        interval: 1,
        repetitions: 0,
        nextReviewDate: now,
        lastAccessed: now,
        totalAttempts: 0,
        correctAttempts: 0,
        accessCount: 0,
        focusSessionStrength: 0,
        distractionPenalty: 0,
        created: now,
        modified: now,
      };

      const currentNodes = await this.getLogicNodes();
      const updatedNodes = [...currentNodes, newNode];
      await this.saveLogicNodes(updatedNodes);

      return newNode;
    }
  }

  async updateLogicNode(nodeId: string, updates: Partial<LogicNode>): Promise<LogicNode | null> {
    try {
      // Try Supabase first
      const updatedNode = await this.supabaseService.updateLogicNode(nodeId, updates);

      // Update cache
      const currentNodes = await this.getLogicNodes();
      const nodeIndex = currentNodes.findIndex(node => node.id === nodeId);
      if (nodeIndex !== -1 && updatedNode) {
        currentNodes[nodeIndex] = updatedNode;
        await this.silentCache(HybridStorageService.CACHE_KEYS.LOGIC_NODES, currentNodes);
      }

      return updatedNode;
    } catch (error) {
      console.warn('ðŸ”„ Updating logic node offline');

      // Fallback: Update locally and queue for sync
      const currentNodes = await this.getLogicNodes();
      const nodeIndex = currentNodes.findIndex(node => node.id === nodeId);

      if (nodeIndex !== -1) {
        const updatedNode = { ...currentNodes[nodeIndex], ...updates, modified: new Date() };
        currentNodes[nodeIndex] = updatedNode;
        await this.saveLogicNodes(currentNodes);
        return updatedNode;
      }

      return null;
    }
  }

  // ==================== FOCUS SESSIONS ====================

  async getFocusSessions(): Promise<FocusSession[]> {
    return this.hybridGet(
      () => this.supabaseService.getFocusSessions(),
      HybridStorageService.CACHE_KEYS.FOCUS_SESSIONS,
      []
    );
  }

  async saveFocusSession(session: FocusSession): Promise<void> {
    try {
      await this.supabaseService.saveFocusSession(session);

      // Update cache
      const currentSessions = await this.getFocusSessions();
      await this.silentCache(HybridStorageService.CACHE_KEYS.FOCUS_SESSIONS, [...currentSessions, session]);
    } catch (error) {
      console.warn('ðŸ”„ Saving focus session offline');

      // Fallback: Save locally and queue for sync
      await this.queueForSync(HybridStorageService.CACHE_KEYS.FOCUS_SESSIONS, session);
    }
  }

  async saveFocusSessions(sessions: FocusSession[]): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveFocusSessions(data),
      HybridStorageService.CACHE_KEYS.FOCUS_SESSIONS,
      sessions
    );
  }

  async getFocusSession(sessionId: string): Promise<FocusSession | null> {
    const sessions = await this.getFocusSessions();
    return sessions.find(session => session.id === sessionId) || null;
  }

  // ==================== READING SESSIONS ====================

  async getReadingSessions(): Promise<ReadingSession[]> {
    return this.hybridGet(
      () => this.supabaseService.getReadingSessions(),
      HybridStorageService.CACHE_KEYS.READING_SESSIONS,
      []
    );
  }

  async saveReadingSession(session: ReadingSession): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveReadingSession(data),
      HybridStorageService.CACHE_KEYS.READING_SESSIONS,
      session
    );
  }

  async saveReadingSessions(sessions: ReadingSession[]): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveReadingSessions(data),
      HybridStorageService.CACHE_KEYS.READING_SESSIONS,
      sessions
    );
  }

  // ==================== SOUND SETTINGS ====================

  async getSoundSettings(): Promise<SoundSettings> {
    return this.hybridGet(
      () => this.supabaseService.getSoundSettings(),
      HybridStorageService.CACHE_KEYS.SOUND_SETTINGS,
      { volume: 0.7 }
    );
  }

  async saveSoundSettings(settings: SoundSettings): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveSoundSettings(data),
      HybridStorageService.CACHE_KEYS.SOUND_SETTINGS,
      settings
    );
  }

  // ==================== NEURAL LOGS ====================

  async getNeuralLogs(): Promise<NeuralLogEntry[]> {
    return this.hybridGet(
      () => this.supabaseService.getNeuralLogs(),
      HybridStorageService.CACHE_KEYS.NEURAL_LOGS,
      []
    );
  }

  async appendNeuralLog(entry: NeuralLogEntry): Promise<void> {
    try {
      await this.supabaseService.appendNeuralLog(entry);

      // Update cache
      const currentLogs = await this.getNeuralLogs();
      await this.silentCache(HybridStorageService.CACHE_KEYS.NEURAL_LOGS, [...currentLogs, entry]);
    } catch (error) {
      console.warn('ðŸ”„ Appending neural log offline');

      // Fallback: Save locally and queue for sync
      await this.queueForSync(HybridStorageService.CACHE_KEYS.NEURAL_LOGS, entry);
    }
  }

  // ==================== FOCUS HEALTH METRICS ====================

  async getFocusHealthMetrics(): Promise<FocusHealthMetrics> {
    return this.hybridGet(
      () => this.supabaseService.getFocusHealthMetrics(),
      HybridStorageService.CACHE_KEYS.FOCUS_HEALTH_METRICS,
      {
        streakCount: 0,
        averageFocusRating: 3,
        distractionsPerSession: 0,
        focusEfficiency: 1.0,
        neuralReinforcement: 0,
        dailyFocusTime: 0,
        weeklyFocusTime: 0,
        bestFocusTimeOfDay: 'morning',
        commonDistractionTriggers: [],
        mostDistractiveDays: [],
        focusImprovement: 0,
      }
    );
  }

  async saveFocusHealthMetrics(metrics: FocusHealthMetrics): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveFocusHealthMetrics(data),
      HybridStorageService.CACHE_KEYS.FOCUS_HEALTH_METRICS,
      metrics
    );
  }

  // ==================== DISTRACTION EVENTS ====================

  async getDistractionEvents(sessionId?: string): Promise<DistractionEvent[]> {
    const allEvents = await this.hybridGet(
      () => this.supabaseService.getDistractionEvents(),
      HybridStorageService.CACHE_KEYS.DISTRACTION_EVENTS,
      []
    );

    if (sessionId) {
      return allEvents.filter(event => event.sessionId === sessionId);
    }

    return allEvents;
  }

  async saveDistractionEvent(event: DistractionEvent): Promise<void> {
    try {
      await this.supabaseService.saveDistractionEvent(event);

      // Update cache
      const currentEvents = await this.getDistractionEvents();
      await this.silentCache(HybridStorageService.CACHE_KEYS.DISTRACTION_EVENTS, [...currentEvents, event]);
    } catch (error) {
      console.warn('ðŸ”„ Saving distraction event offline');

      // Fallback: Save locally and queue for sync
      await this.queueForSync(HybridStorageService.CACHE_KEYS.DISTRACTION_EVENTS, event);
    }
  }

  // ==================== SOURCE LINKS ====================

  async getSourceLinks(): Promise<SourceLink[]> {
    return this.hybridGet(
      () => this.supabaseService.getSourceLinks(),
      HybridStorageService.CACHE_KEYS.SOURCE_LINKS,
      []
    );
  }

  async saveSourceLinks(links: SourceLink[]): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveSourceLinks(data),
      HybridStorageService.CACHE_KEYS.SOURCE_LINKS,
      links
    );
  }

  // ==================== DASHBOARD METHODS ====================

  async getCardsDueToday(): Promise<{
    flashcards: (Flashcard | Flashcard)[];
    logicNodes: LogicNode[];
    criticalLogicCount: number;
  }> {
    try {
      // Get all flashcards and logic nodes
      const [flashcards, logicNodes] = await Promise.all([
        this.getFlashcards(),
        this.getLogicNodes(),
      ]);

      // Use SpacedRepetitionService to filter due items
      const srs = SpacedRepetitionService.getInstance();

      // Convert flashcards to FSRS format and get due ones
      const fsrsCards = flashcards.map(card => srs.convertLegacyCard(card));
      const dueFlashcards = srs.getCardsDueToday(fsrsCards);

      // Convert back to original format for compatibility
      const dueFlashcardIds = new Set(dueFlashcards.map(card => card.id));
      const dueFlashcardsOriginal = flashcards.filter(card => dueFlashcardIds.has(card.id));

      // Get due logic nodes
      const currentDate = new Date();
      const dueLogicNodes = logicNodes.filter(node => node.nextReviewDate <= currentDate);

      // Count critical logic nodes (high difficulty or overdue)
      const criticalLogicCount = logicNodes.filter(node =>
        node.difficulty >= 8 || (node.nextReviewDate <= currentDate && node.difficulty >= 6)
      ).length;

      return {
        flashcards: dueFlashcardsOriginal,
        logicNodes: dueLogicNodes,
        criticalLogicCount,
      };
    } catch (error) {
      console.warn('Failed to get cards due today:', error);
      return {
        flashcards: [],
        logicNodes: [],
        criticalLogicCount: 0,
      };
    }
  }

  // ==================== DASHBOARD METHODS ====================

  async calculateCurrentStudyStreak(): Promise<number> {
    try {
      // Get focus sessions to calculate streak
      const sessions = await this.getFocusSessions();

      if (sessions.length === 0) return 0;

      // Sort sessions by date (most recent first)
      const sortedSessions = sessions
        .sort((a, b) => new Date(b.startTime).getTime() - new Date(a.startTime).getTime());

      let streak = 0;
      let currentDate = new Date();
      currentDate.setHours(0, 0, 0, 0); // Start of today

      // Check if there's a session today or yesterday
      const todaySession = sortedSessions.find(session => {
        const sessionDate = new Date(session.startTime);
        sessionDate.setHours(0, 0, 0, 0);
        return sessionDate.getTime() === currentDate.getTime();
      });

      if (!todaySession) {
        // Check yesterday
        const yesterday = new Date(currentDate);
        yesterday.setDate(yesterday.getDate() - 1);
        const yesterdaySession = sortedSessions.find(session => {
          const sessionDate = new Date(session.startTime);
          sessionDate.setHours(0, 0, 0, 0);
          return sessionDate.getTime() === yesterday.getTime();
        });

        if (!yesterdaySession) {
          return 0; // No recent sessions
        }
        currentDate = yesterday;
      }

      // Count consecutive days with sessions
      while (true) {
        const daySession = sortedSessions.find(session => {
          const sessionDate = new Date(session.startTime);
          sessionDate.setHours(0, 0, 0, 0);
          return sessionDate.getTime() === currentDate.getTime();
        });

        if (!daySession) break;

        streak++;
        currentDate.setDate(currentDate.getDate() - 1);
      }

      return streak;
    } catch (error) {
      console.warn('Failed to calculate study streak:', error);
      return 0;
    }
  }

  // ==================== UTILITY METHODS ====================

  async clearAllData(): Promise<void> {
    try {
      // Clear Supabase data
      await this.supabaseService.clearAllData();
    } catch (error) {
      console.warn('Failed to clear Supabase data:', error);
    }

    // Clear all cache
    const cacheKeys = Object.values(HybridStorageService.CACHE_KEYS);
    await Promise.all(cacheKeys.map(key => AsyncStorage.removeItem(key)));

    // Clear sync queue (DB + legacy AsyncStorage) via helper
    try {
      await syncQueue.clearAll();
    } catch (e) {
      console.warn('Failed to clear sync queue via helper:', e);
      try {
        await AsyncStorage.removeItem('@neurolearn/sync_queue');
      } catch (e2) {
        // ignore
      }
    }

    console.log('ðŸ—‘ï¸ All data cleared (Supabase + Cache)');
  }

  async getStorageInfo(): Promise<{
    isOnline: boolean;
    cacheSize: number;
    queueSize: number;
  }> {
    try {
      const { dbItems, legacyItems } = await syncQueue.fetchAll();
      const queueSize = (dbItems?.length || 0) + (legacyItems?.length || 0);

      // Estimate cache size
      // Prefer MMKV for hot keys
      const hotPrefix = HybridStorageService.HOT_KEYS.CONTEXT_CACHE;
      let cacheSize = 0;
      if (MMKVStorageService.isAvailable()) {
        const hotKeys = await MMKVStorageService.getKeysWithPrefix(hotPrefix);
        cacheSize += hotKeys.length;
      }

      const cacheKeys = Object.values(HybridStorageService.CACHE_KEYS);
      const cacheItems = await Promise.all(
        cacheKeys.map(key => AsyncStorage.getItem(key))
      );
      cacheSize += cacheItems.filter(item => item !== null).length;

      return {
        isOnline: this.isOnline,
        cacheSize,
        queueSize,
      };
    } catch (error) {
      return {
        isOnline: this.isOnline,
        cacheSize: 0,
        queueSize: 0,
      };
    }
  }

  // ==================== LEGACY COMPATIBILITY STUBS ====================
  // These methods maintain compatibility with existing code while redirecting to Supabase

  async getStudySessions(): Promise<StudySession[]> {
    return this.hybridGet(
      () => this.supabaseService.getStudySessions(),
      HybridStorageService.CACHE_KEYS.STUDY_SESSIONS,
      []
    );
  }

  async saveStudySession(session: StudySession): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveStudySession(data),
      HybridStorageService.CACHE_KEYS.STUDY_SESSIONS,
      session
    );
  }

  async saveStudySessions(sessions: StudySession[]): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveStudySessions(data),
      HybridStorageService.CACHE_KEYS.STUDY_SESSIONS,
      sessions
    );
  }

  async getProgressData(): Promise<ProgressData> {
    return {
      studyStreak: 1,
      totalFocusTime: 0,
      todayFocusTime: 0,
      lastStudyDate: new Date().toDateString(),
      retentionRate: 0,
      masteredCards: 0,
      completedSessions: 0,
      weeklyData: [],
    };
  }
  async saveProgressData(progress: ProgressData): Promise<void> {}

  // implementations for tasks and memory palaces are provided above

  /**
   * Prune old focus data both in Supabase (if online) and local cache.
   * Best-effort: non-blocking and defensive.
   */
  async pruneOldFocusData(olderThanDays: number = 90): Promise<void> {
    try {
      // Try Supabase prune first
      await this.supabaseService.pruneOldFocusData(olderThanDays);
    } catch (error) {
      console.warn('Supabase pruneOldFocusData failed or unavailable:', error);
    }

    try {
      // Clean local AsyncStorage cache entries to avoid stale large caches
      await AsyncStorage.removeItem(HybridStorageService.CACHE_KEYS.FOCUS_SESSIONS);
    } catch (error) {
      console.warn('Failed to prune local focus cache:', error);
    }
  }



  // ==================== SLEEP ENTRIES ====================

  async getSleepEntries(userId: string, days: number = 30): Promise<any[]> {
    return this.hybridGet(
      () => this.supabaseService.getSleepEntries(userId, days),
      HybridStorageService.CACHE_KEYS.SLEEP_ENTRIES,
      []
    );
  }

  async saveSleepEntries(userId: string, entries: any[]): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveSleepEntries(userId, data),
      HybridStorageService.CACHE_KEYS.SLEEP_ENTRIES,
      entries
    );
  }

  // ==================== HEALTH DATA METHODS ====================

  async getLastSleepEntry(userId: string): Promise<any> {
    const entries = await this.getSleepEntries(userId, 7);
    return entries.length > 0 ? entries[0] : null;
  }

  async getUserHealthProfile(userId: string): Promise<any> {
    const healthMetrics = await this.getHealthMetrics(userId);
    const sleepEntries = await this.getSleepEntries(userId, 30);

    if (sleepEntries.length === 0) {
      return {
        avgSleepCycleLength: 90,
        sleepDebt: 0,
        avgSleepQuality: healthMetrics.sleepQuality || 7,
        avgSleepDuration: healthMetrics.sleepHours || 8,
      };
    }

    const avgSleepDuration = sleepEntries.reduce((sum, entry) => sum + entry.duration, 0) / sleepEntries.length;
    const avgSleepQuality = sleepEntries.reduce((sum, entry) => sum + entry.quality, 0) / sleepEntries.length;
    const sleepDebt = Math.max(0, (8 - avgSleepDuration) * 60); // Sleep debt in minutes

    return {
      avgSleepCycleLength: 90, // Default circadian rhythm
      sleepDebt,
      avgSleepQuality: Math.round(avgSleepQuality),
      avgSleepDuration: Math.round(avgSleepDuration * 10) / 10,
    };
  }

  async getMovementData(userId: string, days: number): Promise<any[]> {
    // Stub implementation - return empty array for now
    // Could be extended to integrate with fitness trackers
    return [];
  }

  // ==================== HABIT FORMATION METHODS ====================

  async getHabit(userId: string, habitId: string): Promise<any> {
    // Stub implementation - return default habit
    return {
      id: habitId,
      userId,
      habitType: 'exercise',
      targetBehavior: 'Daily walk',
      frequency: 'daily',
      difficulty: 3,
      currentStreak: 5,
      longestStreak: 10,
      completionRate: 0.7,
      triggers: ['Morning alarm'],
      rewards: ['Healthy snack'],
      createdAt: new Date()
    };
  }

  async getHabitCompletionHistory(userId: string, habitId: string, days: number): Promise<any[]> {
    // Stub implementation - return mock history
    const history = [];
    for (let i = 0; i < days; i++) {
      history.push({
        date: new Date(Date.now() - i * 24 * 60 * 60 * 1000).toISOString().split('T')[0],
        completed: Math.random() > 0.3,
        triggerUsed: Math.random() > 0.5
      });
    }
    return history;
  }

  async getUserHabits(userId: string): Promise<any[]> {
    // Stub implementation - return mock habits
    return [
      {
        id: '1',
        userId,
        habitType: 'exercise',
        targetBehavior: 'Daily walk',
        frequency: 'daily',
        difficulty: 3,
        currentStreak: 5,
        longestStreak: 10,
        completionRate: 0.7,
        triggers: ['Morning alarm'],
        rewards: ['Healthy snack'],
        createdAt: new Date()
      }
    ];
  }

  async getRewardHistory(userId: string, days: number): Promise<any[]> {
    // Stub implementation - return mock reward history
    const history = [];
    for (let i = 0; i < days; i++) {
      history.push({
        date: new Date(Date.now() - i * 24 * 60 * 60 * 1000).toISOString().split('T')[0],
        amount: Math.floor(Math.random() * 10),
        type: 'completion'
      });
    }
    return history;
  }

  // ==================== BUDGET ANALYSIS ====================

  async getBudgetAnalysis(userId: string): Promise<any> {
    return this.hybridGet(
      () => this.supabaseService.getBudgetAnalysis(userId),
      HybridStorageService.CACHE_KEYS.BUDGET_ANALYSIS,
      {
        userId,
        categories: [],
        savingsRate: 0,
        totalIncome: 0,
        totalExpenses: 0,
        budgetUtilization: 0,
        lastUpdated: new Date().toISOString(),
      }
    );
  }

  async saveBudgetAnalysis(userId: string, analysis: any): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveBudgetAnalysis(userId, data),
      HybridStorageService.CACHE_KEYS.BUDGET_ANALYSIS,
      analysis
    );
  }

  // ==================== GENERIC ITEM METHODS ====================

  async getItem(key: string): Promise<any> {
    try {
      const value = await AsyncStorage.getItem(key);
      return value ? JSON.parse(value) : null;
    } catch (error) {
      console.error('Error getting item from storage:', error);
      return null;
    }
  }

  async setItem(key: string, value: any): Promise<void> {
    try {
      await AsyncStorage.setItem(key, JSON.stringify(value));
    } catch (error) {
      console.error('Error setting item in storage:', error);
    }
  }

  // ==================== USER PROGRESS HELPERS ====================
  // Provide typed helpers for Gamification and analytics modules.
  async getUserProgress(userId: string): Promise<any | null> {
    try {
      // Prefer Supabase cold tier when online if a dedicated table exists.
      // For now, use AsyncStorage-backed key as a warm cache while supabase
      // support may be added later.
      const key = `user_progress_${userId}`;
      const raw = await this.getItem(key);
      return raw;
    } catch (error) {
      console.error('getUserProgress failed:', error);
      return null;
    }
  }

  async saveUserProgress(userId: string, progress: any): Promise<void> {
    try {
      const key = `user_progress_${userId}`;
      // Attempt to save to Supabase if online - best-effort
      try {
        if (this.isOnline && this.supabaseService && typeof this.supabaseService.saveUserProgress === 'function') {
          await (this.supabaseService as any).saveUserProgress(userId, progress);
        }
      } catch (e) {
        // ignore supabase failures and fallback to local cache
      }

      await this.setItem(key, progress);
    } catch (error) {
      console.error('saveUserProgress failed:', error);
    }
  }

  // ==================== CAE 2.0: CONTEXT STORAGE METHODS ====================

  async saveContextSnapshot(snapshot: any): Promise<void> {
    // First, try to persist to warm-tier DB for local queryability
    try {
      await database.write(async () => {
        const col = database.collections.get('context_snapshots');

        const timestamp = snapshot.timestamp ? (new Date(snapshot.timestamp)).getTime() : Date.now();
        const contextHash = snapshot.contextHash || `${snapshot.sessionId || 'anon'}_${timestamp}`;
        const version = snapshot.version || 1;
        const userId = snapshot.userId || null;

        // Best-effort: if a record with same contextHash exists update it (conflict resolution by version)
        let existing: any[] = [];
        try {
          const q = col.query ? col.query() : null;
          if (q) {
            if (typeof q.fetch === 'function') {
              existing = await q.fetch();
            } else if (typeof q.then === 'function') {
              // Some mocks may return a Promise directly
              existing = await q;
            } else if (Array.isArray(q)) {
              existing = q;
            }
          } else if (typeof col.fetch === 'function') {
            existing = await col.fetch();
          } else if (typeof col.fetchAll === 'function') {
            existing = await col.fetchAll();
          }
        } catch (e) {
          console.warn('Warm DB query for existing context snapshots failed:', e);
          existing = [];
        }

        const found: any = existing.find((rec: any) => {
          const raw = rec._raw ?? rec;
          return (raw && (raw.contextHash === contextHash || raw.context_hash === contextHash)) || (rec && rec.contextHash === contextHash);
        });

        if (found && typeof found.update === 'function') {
          // Update only if incoming version is newer or equal (take max)
          // Use merge/tombstone-aware update
          await found.update((r: any) => {
            const incomingVersion = version;
            const existingVersion = r.version || 1;
            const incomingTs = timestamp;
            const existingTs = r.timestamp || r.updated_at || Date.now();

            if (snapshot.deleted) {
              r.deleted = true;
              r.deleted_at = Date.now();
              r.synced = false;
              r.updated_at = Date.now();
              r.payload = JSON.stringify({ ...(JSON.parse(r.payload || '{}')), ...snapshot });
              return;
            }

            if (incomingVersion > existingVersion) {
              r.timestamp = timestamp;
              r.sessionId = snapshot.sessionId || r.sessionId || null;
              r.payload = JSON.stringify(snapshot);
              r.contextHash = contextHash;
              r.version = incomingVersion;
              r.userId = userId || r.userId || null;
              r.synced = false;
              r.updated_at = Date.now();
            } else if (incomingVersion === existingVersion) {
              if (incomingTs >= existingTs) {
                r.timestamp = timestamp;
                r.payload = JSON.stringify({ ...(JSON.parse(r.payload || '{}')), ...snapshot });
                r.synced = false;
                r.updated_at = Date.now();
              }
            }
            // older incoming version -> ignore
          });
        } else if (typeof col.create === 'function') {
          await col.create((r: any) => {
            r.timestamp = timestamp;
            r.sessionId = snapshot.sessionId || null;
            r.payload = JSON.stringify(snapshot);
            r.contextHash = contextHash;
            r.version = version;
            r.userId = userId;
            r.synced = false;
            r.synced_at = null;
            r.created_at = Date.now();
            r.updated_at = Date.now();
          });
        } else {
          // Fallback: try to append to storage via updateById/create-like API
          try {
            if (Array.isArray(existing)) {
              const rec: any = {
                id: `local_${Date.now()}_${Math.random().toString(36).slice(2,8)}`,
                timestamp,
                sessionId: snapshot.sessionId || null,
                payload: JSON.stringify(snapshot),
                contextHash,
                version,
                userId,
                synced: false,
                synced_at: null,
                created_at: Date.now(),
                updated_at: Date.now(),
              };
              existing.push(rec);
              // If fallback supports writeAll via private API, attempt to call it
              if (typeof (col as any).writeAll === 'function') {
                await (col as any).writeAll(existing);
              }
            }
          } catch (e) {
            // Best-effort only
            console.warn('Warm DB fallback append failed:', e);
          }
        }
      });
    } catch (dbErr) {
      // Warm DB unavailable - if it's a disk-full error, avoid further DB/hot writes
      const msg = String((dbErr as any)?.message || dbErr || '').toLowerCase();
      console.warn('Warm DB saveContextSnapshot failed:', dbErr);
      if (msg.includes('sqlite_full') || msg.includes('database or disk is full')) {
        try {
          // Set global unhealthy flag for 5 minutes (only set/log if not already cooling down)
          if (!this.storageUnhealthyUntil || Date.now() >= this.storageUnhealthyUntil) {
            this.storageUnhealthyUntil = Date.now() + (5 * 60 * 1000);
            this.silentSkipAccumulated = 0;
            this.lastSilentLogAt = 0;
            console.warn('Global storage entered cooldown due to SQLITE_FULL; will skip all local cache writes for 5 minutes');
          }
        } catch (e) {}
        try {
          // Persist a minimal legacy queue entry to AsyncStorage to ensure data isn't lost
          const legacyKey = '@neurolearn/sync_queue';
          const raw = await AsyncStorage.getItem(legacyKey);
          let queue: any[] = [];
          try { queue = raw ? JSON.parse(raw) : []; if (!Array.isArray(queue)) queue = []; } catch { queue = []; }
          queue.push({ key: '@neurolearn/cache_context_snapshots', data: snapshot, timestamp: Date.now(), attempts: 0 });
          // Trim to last 50 to avoid unbounded growth on low space devices
          const trimmed = queue.slice(-50);
          await AsyncStorage.setItem(legacyKey, JSON.stringify(trimmed));
        } catch (e) {
          // ignore - best-effort
        }
        // Avoid further hot writes which may also fail; return early
        return;
      }
    }

    // To avoid duplicate warm DB writes (we already persisted above), only write to hot and queue for cold sync
    try {
      await this.writeToHot(snapshot);
    } catch (e) {
      console.warn('saveContextSnapshot: failed to writeToHot', e);
    }

    try {
      await this.queueForSync('@neurolearn/cache_context_snapshots', snapshot);
    } catch (e) {
      console.warn('saveContextSnapshot: failed to queue for sync', e);
    }

    return;
  }

  async getContextSnapshots(startDate?: Date, endDate?: Date, limit?: number): Promise<any[]> {
    // 1) Try hot (MMKV) first when query is recent or small
    try {
      if (MMKVStorageService.isAvailable()) {
        const now = Date.now();
        const hotKeys = await MMKVStorageService.getKeysWithPrefix(HybridStorageService.HOT_KEYS.CONTEXT_SNAPSHOT_PREFIX);
        const hotItems: any[] = [];
        for (const k of hotKeys) {
          try {
            const item = await MMKVStorageService.getObject(k);
            if (!item) continue;
            const ts = item.timestamp || item.created_at || item.createdAt || now;
            // Filter by date range if provided
            if (startDate && ts < startDate.getTime()) continue;
            if (endDate && ts > endDate.getTime()) continue;
            hotItems.push(item);
          } catch (e) {
            // ignore per-item errors
          }
        }

        if (hotItems.length > 0) {
          // Map to expected shape and sort descending by timestamp
          const mapped = hotItems.map((payload: any) => ({
            ...payload,
            contextHash: payload.contextHash || payload.context_hash || null,
            version: payload.version || 1,
            userId: payload.userId || payload.user_id || null,
            // synced flag may be persisted either on the top-level raw object
            // or inside the serialized payload depending on DB implementation.
            synced: (payload.synced ?? false) || (payload.payload ? (() => { try { return JSON.parse(payload.payload)?.synced ?? false; } catch { return false; } })() : false),
            syncedAt: (payload.synced_at ?? payload.syncedAt) ?? (payload.payload ? (() => { try { return JSON.parse(payload.payload)?.synced_at ?? null; } catch { return null; } })() : null),
            timestamp: payload.timestamp || payload.created_at || payload.createdAt || now,
          })).sort((a,b) => b.timestamp - a.timestamp);

          // Merge persisted synced flags from fallback AsyncStorage-backed
          // warm DB so callers see consistent synced state even when the
          // hot cache hasn't been updated yet (common in tests/CI).
          try {
            const dbKey = 'db:context_snapshots';
            const rawDb = await AsyncStorage.getItem(dbKey);
            if (rawDb) {
              const arr = JSON.parse(rawDb) as any[];
              for (const stored of arr) {
                const ch = stored.contextHash ?? stored.context_hash ?? null;
                if (!ch) continue;
                const found = mapped.find((r: any) => r.contextHash === ch);
                if (found) {
                  found.synced = found.synced || stored.synced || (stored.payload ? (() => { try { return JSON.parse(stored.payload)?.synced ?? false; } catch { return false; } })() : false);
                  found.syncedAt = found.syncedAt || stored.synced_at || (stored.payload ? (() => { try { return JSON.parse(stored.payload)?.synced_at ?? null; } catch { return null; } })() : null);
                }
              }
            }
          } catch (e) {
            // ignore merge errors and just return hot results
          }

          return limit ? mapped.slice(0, limit) : mapped;
        }
      }
    } catch (e) {
      // ignore and fall through to warm DB
    }

    // 2) Try warm DB query for local results
    try {
      const col = database.collections.get('context_snapshots');

      // Fast-path: if the project is using the simple AsyncStorage-backed
      // FallbackDatabase, the underlying key is `db:context_snapshots`; read
      // and return those entries directly to ensure any recently persisted
      // synced flags are reflected (helps test environments/CI).
      try {
        const rawFallback = await AsyncStorage.getItem('db:context_snapshots');
        if (rawFallback) {
          const arr = JSON.parse(rawFallback) as any[];
          let mapped = arr.map((raw: any) => {
            const payload = raw.payload ? (typeof raw.payload === 'string' ? JSON.parse(raw.payload) : raw.payload) : raw;
            return {
              ...payload,
              contextHash: raw.contextHash ?? raw.context_hash ?? payload.contextHash ?? null,
              version: raw.version ?? payload.version ?? 1,
              userId: raw.userId ?? raw.user_id ?? payload.userId ?? null,
              synced: raw.synced ?? (payload && payload.synced) ?? false,
              syncedAt: raw.synced_at ?? raw.syncedAt ?? (payload && payload.synced_at) ?? null,
              timestamp: raw.timestamp ?? payload.timestamp ?? null,
            };
          }).sort((a,b) => (b.timestamp || 0) - (a.timestamp || 0));

          if (startDate) {
            const sd = startDate.getTime();
            mapped = mapped.filter((r: any) => (r.timestamp || 0) >= sd);
          }
          if (endDate) {
            const ed = endDate.getTime();
            mapped = mapped.filter((r: any) => (r.timestamp || 0) <= ed);
          }
          if (limit) mapped = mapped.slice(0, limit);
          if (mapped.length > 0) return mapped;
        }
      } catch (e) {
        // ignore fallback read errors
      }

      const items = await (col.query ? col.query().fetch() : (typeof col.fetch === 'function' ? col.fetch() : []));
  try { console.debug('getContextSnapshots: raw warm items', (items || []).map((it: any) => ({ id: (it._raw??it).id || it.id, contextHash: (it._raw??it).contextHash || (it._raw??it).context_hash || it.contextHash || null, synced: (it._raw??it).synced ?? it.synced ?? false }))); } catch (e) {}
      let results: any[] = items.map((rec: any) => {
        try {
          const raw = rec._raw ?? rec;
          const payload = raw.payload ? JSON.parse(raw.payload) : raw;
          const meta = {
            contextHash: raw.contextHash ?? raw.context_hash ?? payload.contextHash ?? null,
            version: raw.version ?? payload.version ?? 1,
            userId: raw.userId ?? raw.user_id ?? payload.userId ?? null,
            // respect synced either on raw or inside serialized payload
            synced: raw.synced ?? (payload && payload.synced) ?? false,
            syncedAt: raw.synced_at ?? raw.syncedAt ?? (payload && payload.synced_at) ?? null,
            timestamp: raw.timestamp ?? payload.timestamp ?? null,
          };
          return { ...payload, ...meta };
        } catch (e) {
          return rec;
        }
      });

      try {
        // Diagnostic logging to help tests see persisted synced flags in fallback DB
        console.debug('getContextSnapshots: warm DB results', results.map((r: any) => ({ contextHash: r.contextHash, synced: r.synced, syncedAt: r.syncedAt })));
      } catch (e) {}

      // If we have results, attempt to merge any persisted flags from the
      // AsyncStorage-backed fallback DB so callers see consistent synced state.
      try {
        const dbKey = 'db:context_snapshots';
        const rawDb = await AsyncStorage.getItem(dbKey);
        if (rawDb) {
          const arr = JSON.parse(rawDb) as any[];
          for (const stored of arr) {
            const ch = stored.contextHash ?? stored.context_hash ?? (stored.contextHash || null);
            if (!ch) continue;
            const found = results.find((r: any) => r.contextHash === ch);
            if (found) {
              // prefer explicit top-level flag or payload flag
              found.synced = found.synced || stored.synced || (stored.payload ? (() => { try { return JSON.parse(stored.payload)?.synced ?? false; } catch { return false; } })() : false);
              found.syncedAt = found.syncedAt || stored.synced_at || (stored.payload ? (() => { try { return JSON.parse(stored.payload)?.synced_at ?? null; } catch { return null; } })() : null);
            }
          }
        }
      } catch (e) {
        // ignore and continue
      }

      if (startDate) results = results.filter((r: any) => new Date(r.timestamp).getTime() >= startDate.getTime());
      if (endDate) results = results.filter((r: any) => new Date(r.timestamp).getTime() <= endDate.getTime());
      if (limit) results = results.slice(0, limit);

      if (results.length > 0) {
        try { console.debug('getContextSnapshots: final results sample', results.map((r:any)=>({contextHash:r.contextHash,synced:r.synced,syncedAt:r.syncedAt}))); } catch(e){}
        return results;
      }
    } catch (dbErr) {
      // ignore - fallback to Supabase/hybridGet
    }

    // 3) Fallback to cold (Supabase)
    return this.hybridGet(
      () => this.supabaseService.getContextSnapshots(startDate, endDate, limit),
      '@neurolearn/cache_context_snapshots',
      []
    );
  }

  async saveLearnedPattern(pattern: any): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveLearnedPattern(data),
      '@neurolearn/cache_learned_patterns',
      pattern
    );
  }

  async getLearnedPatterns(): Promise<any[]> {
    return this.hybridGet(
      () => this.supabaseService.getLearnedPatterns(),
      '@neurolearn/cache_learned_patterns',
      []
    );
  }

  async saveOptimalLearningWindow(window: any): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveOptimalLearningWindow(data),
      '@neurolearn/cache_optimal_learning_windows',
      window
    );
  }

  async getOptimalLearningWindows(): Promise<any[]> {
    return this.hybridGet(
      () => this.supabaseService.getOptimalLearningWindows(),
      '@neurolearn/cache_optimal_learning_windows',
      []
    );
  }

  async saveKnownLocation(location: any): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveKnownLocation(data),
      '@neurolearn/cache_known_locations',
      location
    );
  }

  async getKnownLocations(): Promise<any[]> {
    return this.hybridGet(
      () => this.supabaseService.getKnownLocations(),
      '@neurolearn/cache_known_locations',
      []
    );
  }

  async saveCognitiveForecast(forecast: any): Promise<void> {
    return this.hybridSet(
      (data) => this.supabaseService.saveCognitiveForecast(data),
      '@neurolearn/cache_cognitive_forecasts',
      forecast
    );
  }

  async getCognitiveForecasts(): Promise<any[]> {
    return this.hybridGet(
      () => this.supabaseService.getCognitiveForecasts(),
      '@neurolearn/cache_cognitive_forecasts',
      []
    );
  }

  // ==================== ADDITIONAL UTILITIES (implemented) ====================

  private async markContextSnapshotsSynced(contextHashes: string[]): Promise<void> {
    try {
      await database.write(async () => {
        const col = database.collections.get('context_snapshots');
          let all: any[] = [];
          try {
            const q = col.query ? col.query() : null;
            if (q && typeof q.fetch === 'function') {
              all = await q.fetch();
            } else if (q && typeof q.then === 'function') {
              all = await q;
            } else if (typeof col.fetch === 'function') {
              all = await col.fetch();
            } else if (Array.isArray(q)) {
              all = q as any[];
            }
          } catch (e) {
            console.warn('Warm DB query for markContextSnapshotsSynced failed:', e);
            all = [];
          }

          const toUpdate = all.filter((rec: any) => {
            const raw = rec._raw ?? rec;
            const ch = raw ? (raw.contextHash ?? raw.context_hash ?? (rec.contextHash || null)) : (rec.contextHash || rec.context_hash || null);
            return ch && contextHashes.includes(ch);
          });
          // Diagnostic: log candidates for update to help debug fallback DB paths
          try {
            console.debug('markContextSnapshotsSynced: candidates count', toUpdate.length);
            console.debug('markContextSnapshotsSynced: contextHashes', contextHashes);
          } catch (e) {}

          const promises = toUpdate.map(async (rec: any) => {
            // Prefer collection-level updateById for persistence (FallbackDatabase implements this)
            try {
              const raw = rec._raw ?? rec;
              const id = raw?.id || rec.id;
              if (id && typeof (col as any).updateById === 'function') {
                try {
                  await (col as any).updateById(id, (r: any) => {
                    r.synced = true;
                    r.synced_at = Date.now();
                    r.updated_at = Date.now();
                  });
                  console.debug('markContextSnapshotsSynced: updated by id', id);
                  return;
                } catch (e) {
                  console.debug('markContextSnapshotsSynced: updateById failed for id', id, e);
                }
              }
            } catch (e) {
              // ignore and try record.update below
              console.debug('markContextSnapshotsSynced: id extraction failed', e);
            }

            if (typeof rec.update === 'function') {
              try {
                await rec.update((r: any) => {
                  r.synced = true;
                  r.synced_at = Date.now();
                  r.updated_at = Date.now();
                });
                try {
                  const raw2 = rec._raw ?? rec;
                  console.debug('markContextSnapshotsSynced: updated record via rec.update id', raw2?.id || rec.id);
                } catch (e) {}
                return;
              } catch (e) {
                console.debug('markContextSnapshotsSynced: rec.update failed', e);
              }
            }

            // As a last resort, try to set a property on the raw object and if collection has a writeAll-like API, attempt it
            try {
              const rawFallback = rec._raw ?? rec;
              if (rawFallback) {
                rawFallback.synced = true;
                rawFallback.synced_at = Date.now();
                rawFallback.updated_at = Date.now();
                if (typeof (col as any).writeAll === 'function') {
                  try {
                    await (col as any).writeAll(all.map((r: any) => (r._raw ?? r)));
                    console.debug('markContextSnapshotsSynced: persisted via writeAll fallback');
                    return;
                  } catch (e) {
                    console.debug('markContextSnapshotsSynced: writeAll fallback failed', e);
                  }
                }
              }
            } catch (e) {
              console.debug('markContextSnapshotsSynced: final fallback failed', e);
            }

            return Promise.resolve();
          });

          await Promise.all(promises);

          // Final verification: some lightweight fallback DBs may not
          // correctly persist via record.update/updateById paths in all
          // environments. Re-fetch and ensure matching records are
          // persisted with synced=true; if the collection exposes a
          // writeAll API, use it as a last-resort batch persist.
          try {
            let refreshed: any[] = [];
            try {
              const q2 = col.query ? col.query() : null;
              if (q2 && typeof q2.fetch === 'function') refreshed = await q2.fetch();
              else if (typeof col.fetch === 'function') refreshed = await col.fetch();
              else refreshed = [];
            } catch (e) {
              refreshed = [];
            }

            const needPersist = [] as any[];
            for (const r of refreshed) {
              const raw = r._raw ?? r;
              const ch = raw ? (raw.contextHash ?? raw.context_hash ?? (r.contextHash || null)) : (r.contextHash || r.context_hash || null);
              if (ch && contextHashes.includes(ch)) {
                if (!raw.synced) {
                  raw.synced = true;
                  raw.synced_at = Date.now();
                  raw.updated_at = Date.now();
                  needPersist.push(raw);
                }
              }
            }

            if (needPersist.length > 0 && typeof (col as any).writeAll === 'function') {
              try {
                await (col as any).writeAll(refreshed.map((r: any) => (r._raw ?? r)));
                console.debug('markContextSnapshotsSynced: persisted via writeAll fallback');
              } catch (e) {
                console.debug('markContextSnapshotsSynced: writeAll fallback failed', e);
              }
            }
          } catch (e) {
            // swallow - this is only best-effort verification
          }

          // Final fallback: if the app is using the simple AsyncStorage-backed
          // FallbackDatabase, directly mutate the underlying storage key to
          // ensure persisted synced flags. This guarantees tests and
          // environments without full DB APIs observe the change.
          try {
            const dbKey = 'db:context_snapshots';
            const raw = await AsyncStorage.getItem(dbKey);
            if (raw) {
              const arr = JSON.parse(raw) as any[];
              try { console.debug('markContextSnapshotsSynced: AsyncStorage raw entries', arr.map((a: any) => ({ id: a.id, contextHash: a.contextHash || a.context_hash, synced: a.synced, payload: a.payload ? (typeof a.payload === 'string' ? a.payload.slice(0,80) : a.payload) : null }))); } catch (e) {}
              let changed = false;
              for (const it of arr) {
                const ch = it.contextHash ?? it.context_hash ?? (it.contextHash || null);
                if (ch && contextHashes.includes(ch)) {
                  if (!it.synced) {
                    it.synced = true;
                    it.synced_at = Date.now();
                    it.updated_at = Date.now();
                    // Also update serialized payload if present so parsers
                    // that inspect payload see the synced flag.
                    try {
                      if (it.payload && typeof it.payload === 'string') {
                        const p = JSON.parse(it.payload);
                        p.synced = true;
                        p.synced_at = it.synced_at;
                        it.payload = JSON.stringify(p);
                      }
                    } catch (e) {
                      // ignore payload parsing errors
                    }
                    changed = true;
                  }
                }
              }
              if (changed) {
                await AsyncStorage.setItem(dbKey, JSON.stringify(arr));
                console.debug('markContextSnapshotsSynced: persisted via AsyncStorage fallback', arr.map((a: any) => ({ contextHash: a.contextHash || a.context_hash, synced: a.synced })));
              }
            }
          } catch (e) {
            // ignore - best-effort only
          }
      });
    } catch (e) {
      console.warn('Failed to mark context snapshots as synced:', e);
    }
  }

  /**
   * Reset sound optimal profiles both in Supabase and local cache.
   */
  async resetOptimalProfiles(): Promise<void> {
    try {
      // Try server-side reset first
      await this.supabaseService.resetOptimalProfiles();
      // Clear local sound settings cache
      await AsyncStorage.removeItem(HybridStorageService.CACHE_KEYS.SOUND_SETTINGS);
      console.log('âœ… Optimal sound profiles reset (Supabase + local cache)');
    } catch (error) {
      console.warn('Failed to reset optimal profiles on Supabase, clearing local cache only:', error);
      // Fallback: clear local cache so the app uses defaults
      try {
        await AsyncStorage.removeItem(HybridStorageService.CACHE_KEYS.SOUND_SETTINGS);
      } catch (e) {
        console.error('Failed to clear local sound settings cache:', e);
      }
    }
  }

  /**
   * Manually trigger storage cleanup to free up space and prevent SQLITE_FULL errors.
   * This runs hot and warm storage cleanup immediately.
   */
  async performStorageCleanup(): Promise<{ hotCleaned: number; warmCleaned: number }> {
    console.log('ðŸ§¹ Performing manual storage cleanup...');
    try {
      const [hotResult, warmResult] = await Promise.all([
        this.cleanupHotStorage(),
        this.cleanupWarmStorage()
      ]);

      const hotCleaned = hotResult.cleaned || 0;
      const warmCleaned = warmResult.cleaned || 0;

      console.log(`âœ… Storage cleanup completed: ${hotCleaned} hot items, ${warmCleaned} warm items removed`);

      return { hotCleaned, warmCleaned };
    } catch (error) {
      console.error('âŒ Storage cleanup failed:', error);
      return { hotCleaned: 0, warmCleaned: 0 };
    }
  }

  /**
   * Export all user data as a JSON string. Best-effort: uses Supabase when online,
   * otherwise composes from local AsyncStorage caches.
   */
  async exportAllData(): Promise<string> {
    try {
      // If online, try to gather from Supabase-backed methods
      if (this.isOnline) {
        const [flashcards, logicNodes, focusSessions, readingSessions, settings, sourceLinks, neuralLogs, soundSettings] = await Promise.all([
          this.getFlashcards(),
          this.getLogicNodes(),
          this.getFocusSessions(),
          this.getReadingSessions(),
          this.getSettings(),
          this.getSourceLinks(),
          this.getNeuralLogs(),
          this.getSoundSettings(),
        ]);

        const payload = {
          flashcards,
          logicNodes,
          focusSessions,
          readingSessions,
          settings,
          sourceLinks,
          neuralLogs,
          soundSettings,
          exportDate: new Date().toISOString(),
          version: '2.1.0',
        };

        return JSON.stringify(payload, null, 2);
      }
    } catch (error) {
      console.warn('Export via Supabase failed, will attempt local cache export:', error);
    }

    // Fallback: assemble from local AsyncStorage caches
    try {
      const keys = Object.values(HybridStorageService.CACHE_KEYS);
      const entries = await Promise.all(keys.map(async (k) => {
        try {
          const v = await AsyncStorage.getItem(k);
          return [k, v ? JSON.parse(v) : null] as const;
        } catch (e) {
          return [k, null] as const;
        }
      }));

      const payload: any = {};
      for (const [k, v] of entries) {
        // Map cache keys to friendly names
        switch (k) {
          case HybridStorageService.CACHE_KEYS.FLASHCARDS:
            payload.flashcards = v || [];
            break;
          case HybridStorageService.CACHE_KEYS.LOGIC_NODES:
            payload.logicNodes = v || [];
            break;
          case HybridStorageService.CACHE_KEYS.FOCUS_SESSIONS:
            payload.focusSessions = v || [];
            break;
          case HybridStorageService.CACHE_KEYS.READING_SESSIONS:
            payload.readingSessions = v || [];
            break;
          case HybridStorageService.CACHE_KEYS.SETTINGS:
            payload.settings = v || {};
            break;
          case HybridStorageService.CACHE_KEYS.SOURCE_LINKS:
            payload.sourceLinks = v || [];
            break;
          case HybridStorageService.CACHE_KEYS.NEURAL_LOGS:
            payload.neuralLogs = v || [];
            break;
          case HybridStorageService.CACHE_KEYS.SOUND_SETTINGS:
            payload.soundSettings = v || {};
            break;
          default:
            // ignore
        }
      }

      payload.exportDate = new Date().toISOString();
      payload.version = '2.1.0';

      return JSON.stringify(payload, null, 2);
    } catch (err) {
      console.error('Failed to export local caches:', err);
      // As a last resort return an empty JSON wrapper
      return JSON.stringify({ exportDate: new Date().toISOString(), version: '2.1.0' });
    }
  }

}

export default HybridStorageService;
